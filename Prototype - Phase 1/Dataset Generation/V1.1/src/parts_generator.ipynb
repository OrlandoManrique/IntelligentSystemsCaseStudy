{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a00826a0-7454-47fe-95aa-c9fdf09a5035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading parameters...\n",
      "Parameters loaded.\n",
      "Generating 50 unique records...\n",
      "Generation complete. Shape: (50, 9)\n",
      "Saved to: C:\\Users\\arthu\\Desktop\\DIT\\CS IntSys\\REPO\\IntelligentSystemsCaseStudy\\Prototype - Phase 1\\Dataset Generation\\V1.1\\data\\generated\\synthetic_parts_generated.csv\n",
      "------------------------------\n",
      "    ITEM_ID            ITEM_DESC  LEN_MM  WID_MM  DEP_MM   WT_KG  QTY_PER_BOX  \\\n",
      "0  53839544  SYNTH_PART_53839544   223.2   104.9   103.5   0.350            1   \n",
      "1  14290145  SYNTH_PART_14290145   562.3   520.0   125.9  10.053            1   \n",
      "2  40451512  SYNTH_PART_40451512   174.1   119.7    91.4   0.192            1   \n",
      "3  41550450  SYNTH_PART_41550450    36.8    36.8    36.8   0.068            1   \n",
      "4  80134182  SYNTH_PART_80134182    64.8    64.8    55.6   0.319            7   \n",
      "5  31286015  SYNTH_PART_31286015   486.0   269.6   145.8   6.368           18   \n",
      "6  56342703  SYNTH_PART_56342703   450.3   112.6   112.6   3.980            1   \n",
      "7  28558716  SYNTH_PART_28558716   410.4   219.0   189.3   6.083            1   \n",
      "8  53514613  SYNTH_PART_53514613   230.2    87.9    87.9   1.432            1   \n",
      "9  93656216  SYNTH_PART_93656216   272.1   272.1    93.4   6.136            1   \n",
      "\n",
      "   BOXES_ON_HAND  DEMAND  \n",
      "0              6       8  \n",
      "1              1       5  \n",
      "2              4       0  \n",
      "3              2       2  \n",
      "4              4       1  \n",
      "5             71       1  \n",
      "6              2      47  \n",
      "7              1       8  \n",
      "8             11       0  \n",
      "9              1       0  \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "# ===============================\n",
    "# Synthetic Data Generation\n",
    "# ===============================\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Configuration & Data Loading\n",
    "# -------------------------------\n",
    "\n",
    "# For Jupyter: current working directory\n",
    "BASE_DIR = Path.cwd()\n",
    "\n",
    "# Go up one level (adjust if needed)\n",
    "PROJECT_ROOT = BASE_DIR.parent\n",
    "\n",
    "# Relative data dirs\n",
    "base_path = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "output_dir = PROJECT_ROOT / \"data\" / \"generated\"\n",
    "\n",
    "print(\"Loading parameters...\")\n",
    "\n",
    "# Load Conditional Rules (for bin selection)\n",
    "conditional_rules_df = pd.read_csv(base_path / \"conditional_rules.csv\")\n",
    "\n",
    "# Load Ratio Stats (for dimension sanity checks)\n",
    "with open(base_path / \"ratio_stats.json\", \"r\") as f:\n",
    "    ratio_stats = json.load(f)\n",
    "\n",
    "# Load Summary Stats (for distributions)\n",
    "summary_stats_df = pd.read_csv(base_path / \"summary_stats.csv\", index_col=0)\n",
    "\n",
    "print(\"Parameters loaded.\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Statistical Prep (Log-Normal)\n",
    "# -------------------------------\n",
    "def get_lognorm_params(row_name):\n",
    "    \"\"\"\n",
    "    Converts arithmetic Mean and Std (from summary_stats.csv) \n",
    "    into Mu and Sigma for the LogNormal distribution.\n",
    "    \"\"\"\n",
    "    stats = summary_stats_df.loc[row_name]\n",
    "    m = stats[\"mean\"]\n",
    "    v = stats[\"std\"] ** 2\n",
    "    \n",
    "    # Formula to convert arithmetic stats to log-space stats\n",
    "    phi = np.sqrt(v + m**2)\n",
    "    mu = np.log(m**2 / phi)\n",
    "    sigma = np.sqrt(np.log(phi**2 / m**2))\n",
    "    \n",
    "    return {\n",
    "        \"mu\": mu, \n",
    "        \"sigma\": sigma, \n",
    "        \"min\": stats[\"min\"], \n",
    "        \"max\": stats[\"max\"]\n",
    "    }\n",
    "\n",
    "# Pre-calculate parameters for the skewed fields\n",
    "qty_params = get_lognorm_params(\"QTY_PER_BOX\")\n",
    "box_params = get_lognorm_params(\"BOXES_ON_HAND\")\n",
    "dem_params = get_lognorm_params(\"DEMAND\")\n",
    "\n",
    "# Pre-calculate bin weights to speed up the loop\n",
    "bin_weights = conditional_rules_df[\"ROW_COUNT\"] / conditional_rules_df[\"ROW_COUNT\"].sum()\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Generator Functions\n",
    "# -------------------------------\n",
    "\n",
    "def _generate_single_row(item_id):\n",
    "    \"\"\"\n",
    "    Internal helper to generate dimensions and stats for a single item.\n",
    "    \"\"\"\n",
    "    # ----- Select length bin -----\n",
    "    chosen_bin = np.random.choice(conditional_rules_df[\"LEN_BIN\"], p=bin_weights)\n",
    "    bin_data = conditional_rules_df[conditional_rules_df[\"LEN_BIN\"] == chosen_bin].iloc[0]\n",
    "\n",
    "    # ----- Sample core dimensions (Uniform within bin range) -----\n",
    "    length = np.random.uniform(bin_data[\"LEN_MIN\"], bin_data[\"LEN_MAX\"])\n",
    "    width  = np.random.uniform(bin_data[\"WID_Q10\"], bin_data[\"WID_Q90\"])\n",
    "    depth  = np.random.uniform(bin_data[\"DEP_Q10\"], bin_data[\"DEP_Q90\"])\n",
    "    weight = np.random.uniform(bin_data[\"WT_Q10\"],  bin_data[\"WT_Q90\"])\n",
    "\n",
    "    # ----- Ratio-based sanity corrections -----\n",
    "    w_l_min, w_l_max = ratio_stats[\"W_L_RATIO_Q10\"], ratio_stats[\"W_L_RATIO_Q90\"]\n",
    "    d_w_min, d_w_max = ratio_stats[\"D_W_RATIO_Q10\"], ratio_stats[\"D_W_RATIO_Q90\"]\n",
    "    wt_v_min, wt_v_max = ratio_stats[\"WT_VOL_RATIO_Q10\"], ratio_stats[\"WT_VOL_RATIO_Q90\"]\n",
    "\n",
    "    # Clip dimensions to ensure realistic aspect ratios\n",
    "    width = np.clip(width, w_l_min * length, w_l_max * length)\n",
    "    depth = np.clip(depth, d_w_min * width, d_w_max * width)\n",
    "    \n",
    "    # Clip weight based on volume\n",
    "    vol = length * width * depth\n",
    "    weight = np.clip(weight, wt_v_min * vol, wt_v_max * vol)\n",
    "\n",
    "    # ----- Log-Normal Distribution Generation (Inventory/Demand) -----\n",
    "    \n",
    "    # 1. QTY_PER_BOX\n",
    "    q_val = np.random.lognormal(qty_params[\"mu\"], qty_params[\"sigma\"])\n",
    "    qty_per_box = int(np.clip(np.round(q_val), qty_params[\"min\"], qty_params[\"max\"]))\n",
    "\n",
    "    # 2. BOXES_ON_HAND\n",
    "    b_val = np.random.lognormal(box_params[\"mu\"], box_params[\"sigma\"])\n",
    "    boxes_on_hand = int(np.clip(np.round(b_val), box_params[\"min\"], box_params[\"max\"]))\n",
    "\n",
    "    # 3. DEMAND\n",
    "    d_val = np.random.lognormal(dem_params[\"mu\"], dem_params[\"sigma\"])\n",
    "    demand = int(np.clip(np.round(d_val), dem_params[\"min\"], dem_params[\"max\"]))\n",
    "\n",
    "    # ----- Description Generation -----\n",
    "    item_desc = f\"SYNTH_PART_{item_id}\"\n",
    "\n",
    "    # ----- Return Row Dictionary -----\n",
    "    return {\n",
    "        \"ITEM_ID\": str(item_id),\n",
    "        \"ITEM_DESC\": item_desc,\n",
    "        \"LEN_MM\": round(length * 10, 1),\n",
    "        \"WID_MM\": round(width  * 10, 1),\n",
    "        \"DEP_MM\": round(depth  * 10, 1),\n",
    "        \"WT_KG\": round(weight, 3),\n",
    "        \"QTY_PER_BOX\": qty_per_box,\n",
    "        \"BOXES_ON_HAND\": boxes_on_hand,\n",
    "        \"DEMAND\": demand\n",
    "    }\n",
    "\n",
    "def generate_synthetic_dataset(num_records):\n",
    "    \"\"\"\n",
    "    Main function to generate a dataset of size num_records.\n",
    "    Guarantees unique numeric IDs.\n",
    "    \"\"\"\n",
    "    print(f\"Generating {num_records} unique records...\")\n",
    "    \n",
    "    # 1. Generate a pool of UNIQUE 8-digit IDs (10M to 99M)\n",
    "    # random.sample throws an error if num_records > range, but 10M-99M is ~90M slots.\n",
    "    # It guarantees no duplicates.\n",
    "    id_pool = random.sample(range(10_000_000, 99_999_999), num_records)\n",
    "    \n",
    "    # 2. Generate data rows\n",
    "    data = [_generate_single_row(uid) for uid in id_pool]\n",
    "    \n",
    "    # 3. Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    print(f\"Generation complete. Shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Execution\n",
    "# -------------------------------\n",
    "# Set the desired number of records\n",
    "N = 50 \n",
    "\n",
    "# Generate\n",
    "df_synth = generate_synthetic_dataset(N)\n",
    "\n",
    "# Save\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"synthetic_parts_generated.csv\")\n",
    "\n",
    "df_synth.to_csv(output_path, sep=';', index=False)\n",
    "\n",
    "print(f\"Saved to: {output_path}\")\n",
    "print(\"-\" * 30)\n",
    "print(df_synth.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
