{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c38855d-138f-4fba-baf5-ddc84b2877ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV files...\n",
      "Processing 10 items against 357 locations...\n",
      "Allocated Item 79924774: 7 units in A1-00001\n",
      "Allocated Item 57944315: 16 units in A2-00001\n",
      "Allocated Item 15900455: 1 units in A1-00002\n",
      "  -> CRITICAL: Item 44318341 too big for any empty location.\n",
      "Allocated Item 71552588: 1 units in A1-00003\n",
      "Allocated Item 76839292: 1 units in A3-00001\n",
      "Allocated Item 68411238: 1 units in A1-00004\n",
      "Allocated Item 39515365: 2 units in A3-00002\n",
      "Allocated Item 85862494: 6 units in A3-00003\n",
      "Allocated Item 85862494: 2 units in A2-00002\n",
      "Allocated Item 13306221: 1 units in A3-00004\n",
      "\n",
      "Allocation complete. Results saved to 'allocations.csv'.\n",
      "\n",
      "--- FINAL DATASET PREVIEW ---\n",
      "  loc_inst_code LOCATION_TYPE   ITEM_ID  QTY_ALLOCATED  MAX_UNITS  GRID_X  GRID_Y  GRID_Z  FULL_LAYERS  PARTIAL_UNITS  ORIENT_X_MM  ORIENT_Y_MM  ORIENT_Z_MM  LOCATION_VOL_MM3  LOCATION_VOL_M3  STORED_VOL_M3  UTILIZATION_PCT\n",
      "0      A1-00001            A1  79924774              7         12       2       6       1            0              7         70.0         97.3        101.9        12480000.0           0.0125         0.0049            38.93\n",
      "1      A2-00001            A2  57944315             16         63       1      21       3            0             16        227.8         37.1         72.4        41712000.0           0.0417         0.0098            23.47\n",
      "2      A1-00002            A1  15900455              1          1       1       1       1            1              0        122.1        488.3        122.1        12480000.0           0.0125         0.0073            58.33\n",
      "3      A1-00003            A1  71552588              1         12       1       4       3            0              1        141.3        141.3         33.4        12480000.0           0.0125         0.0007             5.34\n",
      "4      A3-00001            A3  76839292              1          4       1       2       2            0              1        296.1        296.1         88.2        90610000.0           0.0906         0.0077             8.53\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# --- Configuration for Console Display ---\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 2000)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "def calculate_stacking(loc_dims, item_dims):\n",
    "    \"\"\"\n",
    "    Calculates how many items fit into a location given a specific orientation.\n",
    "    Returns: \n",
    "        total_qty (int): Max quantity\n",
    "        grid_counts (tuple): (count_x, count_y, count_z)\n",
    "    \"\"\"\n",
    "    # Floor division to see how many fit along each axis\n",
    "    count_x = int(loc_dims[0] // item_dims[0])\n",
    "    count_y = int(loc_dims[1] // item_dims[1])\n",
    "    count_z = int(loc_dims[2] // item_dims[2])\n",
    "    \n",
    "    return count_x * count_y * count_z, (count_x, count_y, count_z)\n",
    "\n",
    "def find_best_fit(qty_needed, item_dims_mm, valid_locations):\n",
    "    \"\"\"\n",
    "    Finds the best location and orientation for the given item.\n",
    "    \"\"\"\n",
    "    candidates = [] \n",
    "    \n",
    "    item_vol = item_dims_mm[0] * item_dims_mm[1] * item_dims_mm[2]\n",
    "    \n",
    "    # 6 Possible Orientations\n",
    "    orientations = list(itertools.permutations(item_dims_mm))\n",
    "\n",
    "    for idx, loc in valid_locations.iterrows():\n",
    "        # Assumes input csv has width, depth, height\n",
    "        loc_dims = (loc['width'], loc['depth'], loc['height'])\n",
    "        loc_vol = loc['width'] * loc['depth'] * loc['height']\n",
    "        \n",
    "        if loc_vol <= 0: continue\n",
    "\n",
    "        best_orient_qty = 0\n",
    "        best_grid = (0, 0, 0)\n",
    "        best_dims = (0, 0, 0)\n",
    "\n",
    "        # Check all 6 orientations for this specific location\n",
    "        for i, orient in enumerate(orientations):\n",
    "            qty, grid = calculate_stacking(loc_dims, orient)\n",
    "            \n",
    "            if qty > best_orient_qty:\n",
    "                best_orient_qty = qty\n",
    "                best_grid = grid\n",
    "                best_dims = orient\n",
    "\n",
    "        if best_orient_qty > 0:\n",
    "            actual_stored = min(best_orient_qty, qty_needed)\n",
    "            utilization = (actual_stored * item_vol) / loc_vol\n",
    "            \n",
    "            candidates.append({\n",
    "                'loc_code': loc['loc_inst_code'],\n",
    "                'loc_idx': idx,\n",
    "                'max_capacity': best_orient_qty,\n",
    "                'utilization': utilization,\n",
    "                'grid': best_grid,       # (GRID_X, GRID_Y, GRID_Z)\n",
    "                'dims': best_dims        # (ORIENT_X, ORIENT_Y, ORIENT_Z)\n",
    "            })\n",
    "\n",
    "    if not candidates:\n",
    "        return None\n",
    "\n",
    "    candidates_df = pd.DataFrame(candidates)\n",
    "    \n",
    "    # Logic 1: Filter for locations that fit the ENTIRE requested quantity\n",
    "    fits_all = candidates_df[candidates_df['max_capacity'] >= qty_needed]\n",
    "    \n",
    "    if not fits_all.empty:\n",
    "        # Highest Utilization\n",
    "        return fits_all.sort_values(by='utilization', ascending=False).iloc[0]\n",
    "    else:\n",
    "        # Logic 2: Highest Capacity, then Utilization\n",
    "        return candidates_df.sort_values(by=['max_capacity', 'utilization'], ascending=[False, False]).iloc[0]\n",
    "\n",
    "def run_allocation():\n",
    "    # File Checks\n",
    "    loc_file = \"locations_dummy.csv\"\n",
    "    parts_file = \"synthetic_parts_generated.csv\"\n",
    "    \n",
    "    if not os.path.exists(loc_file) or not os.path.exists(parts_file):\n",
    "        print(f\"Error: Ensure '{loc_file}' and '{parts_file}' are in the script directory.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Load Data\n",
    "    print(\"Loading CSV files...\")\n",
    "    df_locs = pd.read_csv(loc_file)\n",
    "    df_parts = pd.read_csv(parts_file, sep=\";\")\n",
    "\n",
    "    df_locs['is_occupied'] = False\n",
    "    \n",
    "    allocations = []\n",
    "    \n",
    "    # Processing limit (adjust as needed)\n",
    "    items_to_process = df_parts.head(10)\n",
    "    \n",
    "    print(f\"Processing {len(items_to_process)} items against {len(df_locs)} locations...\")\n",
    "\n",
    "    for index, item in items_to_process.iterrows():\n",
    "        item_id = item['ITEM_ID']\n",
    "        qty_remaining = item['BOXES_ON_HAND']\n",
    "        item_dims = (item['LEN_MM'], item['WID_MM'], item['DEP_MM'])\n",
    "        \n",
    "        # Calculate Item Volume once (mm3)\n",
    "        single_item_vol_mm3 = item_dims[0] * item_dims[1] * item_dims[2]\n",
    "        \n",
    "        while qty_remaining > 0:\n",
    "            available_locs = df_locs[df_locs['is_occupied'] == False]\n",
    "            \n",
    "            if available_locs.empty:\n",
    "                print(f\"  -> CRITICAL: No locations left for Item {item_id}\")\n",
    "                break\n",
    "            \n",
    "            match = find_best_fit(qty_remaining, item_dims, available_locs)\n",
    "            \n",
    "            if match is None:\n",
    "                print(f\"  -> CRITICAL: Item {item_id} too big for any empty location.\")\n",
    "                break\n",
    "                \n",
    "            # Perform Allocation\n",
    "            loc_code = match['loc_code']\n",
    "            loc_idx = match['loc_idx']\n",
    "            max_units = match['max_capacity']\n",
    "            \n",
    "            # Retrieve Grid and Dimensions\n",
    "            grid_x, grid_y, grid_z = match['grid']\n",
    "            orient_x, orient_y, orient_z = match['dims']\n",
    "            \n",
    "            # Calculate Qty\n",
    "            qty_to_store = min(qty_remaining, max_units)\n",
    "            \n",
    "            # Calculate Layers\n",
    "            units_per_layer = grid_x * grid_y\n",
    "            if units_per_layer > 0:\n",
    "                full_layers = qty_to_store // units_per_layer\n",
    "                partial_units = qty_to_store % units_per_layer\n",
    "            else:\n",
    "                full_layers = 0\n",
    "                partial_units = 0\n",
    "            \n",
    "            # --- Volume Calculations ---\n",
    "            # 1. Location Volume\n",
    "            loc_w = df_locs.at[loc_idx, 'width']\n",
    "            loc_d = df_locs.at[loc_idx, 'depth']\n",
    "            loc_h = df_locs.at[loc_idx, 'height']\n",
    "            \n",
    "            loc_vol_mm3 = loc_w * loc_d * loc_h\n",
    "            loc_vol_m3 = loc_vol_mm3 / 1_000_000_000  # Convert mm3 to m3\n",
    "            \n",
    "            # 2. Stored Volume\n",
    "            stored_vol_mm3 = qty_to_store * single_item_vol_mm3\n",
    "            stored_vol_m3 = stored_vol_mm3 / 1_000_000_000 # Convert mm3 to m3\n",
    "            \n",
    "            # 3. Utilization %\n",
    "            final_util = (stored_vol_mm3 / loc_vol_mm3) * 100\n",
    "            \n",
    "            # --- Location Type Logic ---\n",
    "            # Checks if 'type' column exists, otherwise tries to parse from code (e.g., A1 from A1-0001)\n",
    "            if 'type' in df_locs.columns:\n",
    "                loc_type = df_locs.at[loc_idx, 'type']\n",
    "            elif 'LOCATION_TYPE' in df_locs.columns:\n",
    "                loc_type = df_locs.at[loc_idx, 'LOCATION_TYPE']\n",
    "            else:\n",
    "                # Fallback: assume format AA-12345, take first part\n",
    "                loc_type = str(loc_code).split('-')[0]\n",
    "\n",
    "            # Record Results strictly matching target schema\n",
    "            allocations.append({\n",
    "                'loc_inst_code': loc_code,\n",
    "                'LOCATION_TYPE': loc_type,\n",
    "                'ITEM_ID': item_id,\n",
    "                'QTY_ALLOCATED': int(qty_to_store),\n",
    "                'MAX_UNITS': int(max_units),\n",
    "                'GRID_X': int(grid_x),\n",
    "                'GRID_Y': int(grid_y),\n",
    "                'GRID_Z': int(grid_z),\n",
    "                'FULL_LAYERS': int(full_layers),\n",
    "                'PARTIAL_UNITS': int(partial_units),\n",
    "                'ORIENT_X_MM': round(orient_x,1),\n",
    "                'ORIENT_Y_MM': round(orient_y,1),\n",
    "                'ORIENT_Z_MM': round(orient_z,1),\n",
    "                'LOCATION_VOL_MM3': round(loc_vol_mm3, 1),\n",
    "                'LOCATION_VOL_M3': round(loc_vol_m3, 4),\n",
    "                'STORED_VOL_M3': round(stored_vol_m3, 4),\n",
    "                'UTILIZATION_PCT': round(final_util, 2)\n",
    "            })\n",
    "            \n",
    "            print(f\"Allocated Item {item_id}: {qty_to_store} units in {loc_code}\")\n",
    "            \n",
    "            # Update state\n",
    "            df_locs.at[loc_idx, 'is_occupied'] = True\n",
    "            qty_remaining -= qty_to_store\n",
    "\n",
    "    # Export Results\n",
    "    df_allocations = pd.DataFrame(allocations)\n",
    "    output_filename = \"allocations.csv\"\n",
    "    \n",
    "    # Define strict Column Order\n",
    "    cols_order = [\n",
    "        'loc_inst_code',\n",
    "        'LOCATION_TYPE',\n",
    "        'ITEM_ID',\n",
    "        'QTY_ALLOCATED',\n",
    "        'MAX_UNITS',\n",
    "        'GRID_X',\n",
    "        'GRID_Y',\n",
    "        'GRID_Z',\n",
    "        'FULL_LAYERS',\n",
    "        'PARTIAL_UNITS',\n",
    "        'ORIENT_X_MM',\n",
    "        'ORIENT_Y_MM',\n",
    "        'ORIENT_Z_MM',\n",
    "        'LOCATION_VOL_MM3',\n",
    "        'LOCATION_VOL_M3',\n",
    "        'STORED_VOL_M3',\n",
    "        'UTILIZATION_PCT'\n",
    "    ]\n",
    "    \n",
    "    if not df_allocations.empty:\n",
    "        # Reorder columns\n",
    "        df_allocations = df_allocations[cols_order]\n",
    "        \n",
    "        # Save to CSV\n",
    "        df_allocations.to_csv(output_filename, index=False)\n",
    "        print(f\"\\nAllocation complete. Results saved to '{output_filename}'.\")\n",
    "        \n",
    "        # Preview\n",
    "        print(\"\\n--- FINAL DATASET PREVIEW ---\")\n",
    "        print(df_allocations.head(5).to_string())\n",
    "    else:\n",
    "        print(\"No allocations were made.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_allocation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
